{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will look at modelling the affect of gravity on falling objects, by producing data mimicing these objects and then create machine learning models that learn from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling $y = x_0 + v_0t - \\frac{1}{2}gt^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a function to calculate the position of a object after dropping it. This is found with the above formula. Note that,\n",
    "\n",
    "$x_0 =$ initial position\n",
    "\n",
    "$v_0 =$ initial velocty\n",
    "\n",
    "$g =~ 9.8 m/s^2$ (approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(x_0, v_0, t):\n",
    "    return x_0 + v_0*t - (9.8/2)*t**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a dataset, based on random input values, with the location of the object calculated from the function above. Note that we will include the mass as a variable, even though it is irrelevant to the resulting location. We will see how our machine learning algorithm handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "random.seed\n",
    "\n",
    "with open('gravity_location_data.csv', mode='w') as gravity_file:\n",
    "    gravity_writer = csv.writer(gravity_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    gravity_writer.writerow(['initial_position', 'initial_velocity', 'mass', 'time', 'location'])\n",
    "\n",
    "    for i in range (0, 10000):\n",
    "        initial_position = random.randrange(1, 10000)\n",
    "        initial_velocity = random.randrange(1, 100)\n",
    "        mass = random.randrange(1, 1000)\n",
    "        time = random.randrange(1, 100)\n",
    "\n",
    "        gravity_writer.writerow([initial_position, initial_velocity, mass, time, location(initial_position, initial_velocity, time)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get this dataset into our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gravity_data = pd.read_csv('gravity_location_data.csv')\n",
    "df_location = pd.DataFrame(gravity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to split the data into training and testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data, target_name):\n",
    "    y = data[target_name]\n",
    "    X = data.drop(target_name, axis=1)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a function that can accept our train and test data, train a model on this data, and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def train_eval_poly(X_train, X_test, y_train, y_test):\n",
    "    regression_model = LinearRegression() \n",
    "    \n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    X_train_transform = poly.fit_transform(X_train)\n",
    "    X_test_transform = poly.fit_transform(X_test)\n",
    "    \n",
    "    regression_model.fit(X_train_transform, y_train)\n",
    "    \n",
    "    print(poly.fit(X_train).get_feature_names(X_train.columns))\n",
    "    \n",
    "    y_pred = regression_model.predict(X_test_transform)\n",
    "    print(\"R2: \\t\", r2_score(y_test, y_pred))\n",
    "    print(\"RMSE: \\t\", sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"MAE: \\t\", mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    return regression_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our functions to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'initial_position', 'initial_velocity', 'mass', 'time', 'initial_position^2', 'initial_position initial_velocity', 'initial_position mass', 'initial_position time', 'initial_velocity^2', 'initial_velocity mass', 'initial_velocity time', 'mass^2', 'mass time', 'time^2']\n",
      "R2: \t 1.0\n",
      "RMSE: \t 2.999978554169189e-09\n",
      "MAE: \t 2.4458151883788302e-09\n"
     ]
    }
   ],
   "source": [
    "df_split = split_data(df_location, 'location')\n",
    "lrModel = train_eval_poly(*df_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation shows very good results, particularly the $r^2$ of 1.0! Now let's look at the coefficients produced on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  1.00000000e+00, -6.75868639e-13, -2.45002508e-14,\n",
       "        4.20460132e-13,  2.39542363e-16,  1.80762368e-17, -2.55803435e-17,\n",
       "        4.07539983e-16, -9.27300961e-15, -6.81456968e-16,  1.00000000e+00,\n",
       "        4.59909681e-16, -1.63791735e-15, -4.90000000e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients match the output of the bracketed array in the previous results. Note most of these values are extermely small--they are essentially zero. This includes the value for mass, because the training operation was able to determine, more or less, that this value is irrelevant. The final value is the gravity constant, or more specifically, $-g/2$ or $-9.8/2$. Finally, the second and twelfth values are 1. These correspond to initial_position initial_velocity*time.\n",
    "\n",
    "In other words, this set of coefficients show that we have trained a model that corresponds to the equation of a falling object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at a slightly harder problem, which is, predicting the time it will take an object to hit the ground, falling from a certain height at a certain initial velocity. First, we calculate the \"fall time\", which is the same as our equation for a falling object, but we solve for t. This gives us..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $t = -v_0 - \\frac{\\sqrt{v_0^2 + 19.2x_0}}{-9.8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function that will calculate the fall time of an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fall_time(initial_position, initial_velocity):\n",
    "    a = -9.8 / 2\n",
    "    b = initial_velocity\n",
    "    c = initial_position\n",
    "    \n",
    "    time = (-1 * b - math.sqrt(b**2 + 19.6*c)) / -9.8\n",
    "    return time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a dataset of randomized values, with their resulting fall time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gravity_fall_data.csv', mode='w') as gravity_file:\n",
    "    gravity_writer = csv.writer(gravity_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    gravity_writer.writerow(['initial_position', 'initial_velocity', 'mass', 'fall_time'])\n",
    "\n",
    "    for i in range (0, 10000):\n",
    "        initial_position = random.randrange(1, 10000)\n",
    "        initial_velocity = random.randrange(1, 1000)\n",
    "        mass = random.randrange(1, 1000)\n",
    "\n",
    "        gravity_writer.writerow([initial_position, initial_velocity, mass, fall_time(initial_position, initial_velocity)])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And input it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_data = pd.read_csv('gravity_fall_data.csv')\n",
    "df_fall = pd.DataFrame(gravity_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model based on this data. First we will use strict linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: \t 0.995527175268824\n",
      "RMSE: \t 3.551847761580043\n",
      "MAE: \t 2.752993296307049\n"
     ]
    }
   ],
   "source": [
    "def train_eval_linear(X_train, X_test, y_train, y_test):\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    y_pred = regression_model.predict(X_test)\n",
    "    print(\"R2: \\t\", r2_score(y_test, y_pred))\n",
    "    print(\"RMSE: \\t\", sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"MAE: \\t\", mean_absolute_error(y_test, y_pred))\n",
    "    return regression_model\n",
    "    \n",
    "df_split = split_data(df_fall, 'fall_time')\n",
    "lrModel = train_eval_linear(*df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.94907261e-03, 1.83824083e-01, 4.37656545e-05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite good! Suprisingly so. Now let's try polynomial regresion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'initial_position', 'initial_velocity', 'mass', 'initial_position^2', 'initial_position initial_velocity', 'initial_position mass', 'initial_velocity^2', 'initial_velocity mass', 'mass^2']\n",
      "R2: \t 0.9994631902517299\n",
      "RMSE: \t 1.2304772811300295\n",
      "MAE: \t 0.9315999956362887\n"
     ]
    }
   ],
   "source": [
    "df_split = split_data(df_fall,'fall_time')\n",
    "lrModel = train_eval_poly(*df_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even better! There was not much room for improvement, but we found it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  3.91131574e-03,  1.65739891e-01, -1.46354722e-04,\n",
       "       -5.85570688e-08, -2.74996796e-06,  2.79424189e-09,  3.16862471e-05,\n",
       "        2.24127968e-08,  1.15017972e-07])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, however, that in both cases the coefficients are pretty indecipherable, or at least, they cannot obviously be transformed back to our original equation. That's fine. Machine learning is not necessarily the best way to find the correct equation, but in some cases it does quite well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
